seed: 99
net:
    arch: inception_v4  # inception_v2, inception_v3
    kwargs:
        num_classes: 1000
 
dataset:
  train:
    meta_file: /mnt/lustre/share_data/parrots_algolib/datasets/Imagenet/meta/train.txt
    image_dir: /mnt/lustre/share_data/parrots_algolib/datasets/Imagenet/train
    reader: pillow
    random_resize_crop: 299
    colorjitter: [0.2, 0.2, 0.2, 0.1]
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
    mirror: True
  test:
    meta_file: /mnt/lustre/share_data/parrots_algolib/datasets/Imagenet/meta/val.txt
    image_dir: /mnt/lustre/share_data/parrots_algolib/datasets/Imagenet/val
    reader: pillow
    resize: 331
    center_crop: [299, 299]
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
    mirror: False
  batch_size: 32
  workers: 4
 
trainer:
  max_epoch: 160
  test_freq: 161
  log_freq: 200
  mixed_precision:
    half: True
    loss_scale: 128.0
    float_bn: True
    #float_module_type: "{torch.nn.Conv2d:('float', 'half')}"
    #    #float_module_name: "{'fc':('float', 'half')}"
  optimizer:
    type: SGD
    kwargs:
      lr: 0.1
      momentum: 0.9
      weight_decay: 0.0001
  lr_scheduler:
    warmup_epochs: 0
    type: MultiStepLR
    kwargs:
      milestones: [30,60,90]
      gamma: 0.1
 
saver:
  # pretrian_model: 
  # resume_model: 
  # load_pavi:   # load pretrain/resume model from pavi
  # save_pavi: True   # add snapshot to pavi
  save_dir: algolib_gen/example/checkpoints/inception_v4_mix   # save checkpoint locally
  save_epoch_freq: 160
  save_latest: False
  save_best: True
 
# monitor:
  # type: pavi
  # kwargs:
  #   project: default
  #   task: inception_v4
  #   model: inception_v4
  # type: tensorboard
  # kwargs:
  #     logdir: tensorboard
