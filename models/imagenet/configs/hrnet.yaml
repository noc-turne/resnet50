seed: 99
net:
    arch: HRNet
    kwargs:
        stages:
            STAGE1:
                NUM_MODULES: 1
                NUM_RANCHES: 1
                BLOCK: BOTTLENECK
                NUM_BLOCKS:
                - 4
                NUM_CHANNELS:
                - 64
                FUSE_METHOD: SUM

            STAGE2:
                NUM_MODULES: 1
                NUM_BRANCHES: 2
                BLOCK: BASIC
                NUM_BLOCKS:
                - 4
                - 4
                NUM_CHANNELS:
                - 18
                - 36
                FUSE_METHOD: SUM

            STAGE3:
                NUM_MODULES: 4
                NUM_BRANCHES: 3
                BLOCK: BASIC
                NUM_BLOCKS:
                - 4
                - 4
                - 4
                NUM_CHANNELS:
                - 18
                - 36
                - 72
                FUSE_METHOD: SUM

            STAGE4:
                NUM_MODULES: 3
                NUM_BRANCHES: 4
                BLOCK: BASIC
                NUM_BLOCKS:
                - 4
                - 4
                - 4
                - 4 
                NUM_CHANNELS:
                - 18
                - 36
                - 72
                - 144
                FUSE_METHOD: SUM
        bn:
            use_sync_bn: False
            kwargs: {}

dataset:
  train:
    meta_file: /mnt/lustre/share/images/meta/train.txt
    image_dir: /mnt/lustre/share/images/train
    random_resize_crop: 224
    colorjitter: [0.2, 0.2, 0.2, 0.1]
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
    mirror: True
  test:
    meta_file: /mnt/lustre/share/images/meta/val.txt
    image_dir: /mnt/lustre/share/images/val
    resize: 256
    center_crop: [224, 224]
    colorjitter:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
    mirror: False
  batch_size: 32
  workers: 4
 
trainer:
  max_epoch: 100
  test_freq: 1
  log_freq: 20
  optimizer:
    type: SGD
    kwargs:
      lr: 0.1
      momentum: 0.9
      weight_decay: 0.0001
  lr_scheduler:
    warmup_epochs: 0
    type: MultiStepLR
    kwargs:
      milestones: [30,60,90]
      gamma: 0.1

saver:
  pretrain_model:
  resume_model:
  save_dir: checkpoints/hrnet   # save checkpoint locally
 
monitor:
  type: pavi
  _taskid: # continue training
  kwargs:
    project: default  # change to your own pavi project
    task: hrnet
    model: hrnet
